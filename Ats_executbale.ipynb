{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53e383",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from flask import Flask, render_template, request,jsonify\n",
    "import PyPDF2\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from google.colab.output import eval_js\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from google.colab import drive\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# Initialize Pinecone client\n",
    "# Access the environment variables\n",
    "bearer_token_1 = os.getenv(\"BEARER_TOKEN\")\n",
    "bearer_token_2 = os.getenv(\"BEARER_TOKEN\")\n",
    "google_api = os.getenv(\"GOOGLE_API_KEY\")\n",
    "pinecone_api = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pinecone_api)\n",
    "index_name = \"start1\"\n",
    "app = Flask(__name__)\n",
    "# Create Pinecone index if it doesn't exist\n",
    "def create_index_if_not_exists():\n",
    "    try:\n",
    "        # Check if index already exists\n",
    "        indexes = pc.list_indexes()\n",
    "        if index_name not in [index.name for index in indexes]:\n",
    "            pc.create_index(\n",
    "                name=index_name,\n",
    "                dimension=1024,  # Dimensions for bge-large-en-v1.5\n",
    "                metric=\"cosine\",\n",
    "                spec=ServerlessSpec(\n",
    "                    cloud=\"aws\",\n",
    "                    region=\"us-east-1\"\n",
    "                )\n",
    "            )\n",
    "            print(f\"Index '{index_name}' created successfully\")\n",
    "        else:\n",
    "            print(f\"Index '{index_name}' already exists\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating index: {e}\")\n",
    "def get_drive_folder():\n",
    "  drive.mount('/content/drive')\n",
    "  folder = \"/content/drive/MyDrive/data/Assesment_Dataset/data/data\"\n",
    "\n",
    "# Get a list of all items in the directory\n",
    "  all_items = os.listdir(folder)\n",
    "\n",
    "  # Filter the list to include only folders\n",
    "  folders = [item for item in all_items if os.path.isdir(os.path.join(folder, item))]\n",
    "\n",
    "  return folders\n",
    "def get_folder_name(jd,folders):\n",
    "\n",
    "    url = \"https://api.langflow.astra.datastax.com/lf/ad6e8f21-6c0a-4de7-b59c-837f011e58f2/api/v1/run/e0666050-2c47-4082-bbb3-491a6eb51591?stream=false\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {bearer_token_1}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"input_value\": \"message\",\n",
    "        \"output_type\": \"chat\",\n",
    "        \"input_type\": \"chat\",\n",
    "        \"tweaks\": {\n",
    "            \"Agent-m8iEy\": {\n",
    "                \"add_current_date_tool\": True,\n",
    "                \"agent_description\": \"A smart AI assistant capable of analyzing job descriptions and matching relevant resumes.\",\n",
    "                \"agent_llm\": \"Google Generative AI\",\n",
    "                \"handle_parsing_errors\": True,\n",
    "                \"input_value\": '',\n",
    "                \"max_iterations\": 15,\n",
    "                \"n_messages\": 100,\n",
    "                \"order\": \"Ascending\",\n",
    "                \"sender\": \"Machine and User\",\n",
    "                \"sender_name\": \"\",\n",
    "                \"session_id\": \"\",\n",
    "                \"system_prompt\": \"You are an AI assistant designed to analyze job descriptions and match relevant resumes.\\nEnsure your responses are concise and formatted in Markdown for readability.\",\n",
    "                \"template\": \"**{sender_name}**: {text}\",\n",
    "                \"verbose\": True,\n",
    "                \"model_name\": \"learnlm-1.5-pro-experimental\",\n",
    "                \"api_key\": google_api,\n",
    "                \"temperature\": 0.1,\n",
    "                \"tool_model_enabled\": False\n",
    "            },\n",
    "            \"ChatOutput-PeXVa\": {\n",
    "                \"background_color\": \"\",\n",
    "                \"chat_icon\": \"\",\n",
    "                \"clean_data\": True,\n",
    "                \"data_template\": \"{text}\",\n",
    "                \"input_value\": \"\",\n",
    "                \"sender\": \"Machine\",\n",
    "                \"sender_name\": \"AI\",\n",
    "                \"session_id\": \"\",\n",
    "                \"should_store_message\": True,\n",
    "                \"text_color\": \"\"\n",
    "            },\n",
    "            \"Prompt-aATiG\": {\n",
    "                \"template\": \"    Based on the job description below, determine if resumes stored in a folder with the following name are relevant.\\n    \\n    Job Description:\\n    {job_description}\\n    \\n    Folder Name:\\n    {folder_name}\\n    \\n    Respond with only relevant \\\"Folder Name\\\" present in variable don't by you anything as output with no extra text.\\n\",\n",
    "                \"tool_placeholder\": \"\",\n",
    "                \"job_description\": jd,\n",
    "                \"folder_name\": f\"{folders}\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    response=response.json()\n",
    "    chat_response = response[\"outputs\"][0][\"outputs\"][0][\"results\"][\"message\"][\"data\"][\"text\"]\n",
    "    # print(chat_response)\n",
    "    # folder_names = chat_response.split('/n') # Assuming comma-separated values in chat_response\n",
    "    # folder_names = [name.strip() for name in folder_names] # Remove leading/trail\n",
    "    # print(folder_names)\n",
    "    folder_names = chat_response.split('\\n')  # Split by newline\n",
    "    folder_names = [name.strip() for name in folder_names if name.strip()]\n",
    "    return folder_names\n",
    "# Function to extract text from PDF files in a folder (limited to max_files)\n",
    "def extract_pdf_text(folder_name, max_files=5):\n",
    "    \"\"\"Extract text from PDF files in the specified folder, limited to max_files.\"\"\"\n",
    "    folder_path = f\"/content/drive/MyDrive/data/Assesment_Dataset/data/data/{folder_name}\"\n",
    "    file_data = []\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} does not exist.\")\n",
    "        return file_data\n",
    "\n",
    "    # Get a list of all PDF files in the folder\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith(\".pdf\")]\n",
    "\n",
    "    # Limit to max_files\n",
    "    pdf_files = pdf_files[:max_files]\n",
    "\n",
    "    # Process each file\n",
    "    for filename in pdf_files:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        resume_text = \"\"\n",
    "\n",
    "        # Open and process the PDF file\n",
    "        try:\n",
    "            with open(file_path, 'rb') as pdf_file:\n",
    "                pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "                # Get the number of pages\n",
    "                num_pages = len(pdf_reader.pages)\n",
    "\n",
    "                # Extract text from all pages\n",
    "                for page in range(num_pages):\n",
    "                    page_obj = pdf_reader.pages[page]\n",
    "                    resume_text += page_obj.extract_text()\n",
    "\n",
    "            file_data.append({\n",
    "                \"file_name\": filename,\n",
    "                \"text\": resume_text\n",
    "            })\n",
    "            print(f\"Successfully extracted text from {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {filename}: {e}\")\n",
    "\n",
    "    return file_data\n",
    "\n",
    "# Function to extract text from TXT files in a folder (limited to max_files)\n",
    "def extract_txt_text(folder_name, max_files=5):\n",
    "    \"\"\"Extract text from TXT files in the specified folder, limited to max_files.\"\"\"\n",
    "    folder_path = f\"/content/drive/MyDrive/data/Assesment_Dataset/data/data/{folder_name}\"\n",
    "    file_data = []\n",
    "\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} does not exist.\")\n",
    "        return file_data\n",
    "\n",
    "    # Get a list of all TXT files in the folder\n",
    "    txt_files = [f for f in os.listdir(folder_path) if f.endswith(\".txt\")]\n",
    "\n",
    "    # Limit to max_files\n",
    "    txt_files = txt_files[:max_files]\n",
    "\n",
    "    # Process each file\n",
    "    for filename in txt_files:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        resume_text = \"\"\n",
    "\n",
    "        # Open and process the TXT file\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as txt_file:\n",
    "                resume_text = txt_file.read()\n",
    "\n",
    "            file_data.append({\n",
    "                \"file_name\": filename,\n",
    "                \"text\": resume_text\n",
    "            })\n",
    "            print(f\"Successfully extracted text from {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {filename}: {e}\")\n",
    "\n",
    "    return file_data\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embeddings(text):\n",
    "    \"\"\"Generate embeddings for the given text using the BGE model.\"\"\"\n",
    "    model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "\n",
    "    # Generate embeddings\n",
    "    embedding = model.encode(text)\n",
    "    return embedding\n",
    "\n",
    "# Function to store embeddings in Pinecone\n",
    "def store_embeddings(resume_data, folder_name):\n",
    "    \"\"\"Store embeddings in Pinecone with metadata.\"\"\"\n",
    "    try:\n",
    "        # Get the index\n",
    "        index = pc.Index(index_name)\n",
    "\n",
    "        # Process each resume\n",
    "        for resume in resume_data:\n",
    "            file_name = resume[\"file_name\"]\n",
    "            text = resume[\"text\"]\n",
    "\n",
    "            # Generate embeddings\n",
    "            embedding = generate_embeddings(text)\n",
    "\n",
    "            # Create unique ID\n",
    "            vector_id = f\"{folder_name}_{file_name}_{hash(text) % 10000}\"\n",
    "\n",
    "            # Create metadata\n",
    "            metadata = {\n",
    "                \"folder_name\": folder_name,\n",
    "                \"file_name\": file_name,\n",
    "                \"text_sample\": text # Store a sample of the text\n",
    "            }\n",
    "\n",
    "            # Upsert the embedding with metadata\n",
    "            index.upsert(\n",
    "                vectors=[\n",
    "                    {\n",
    "                        \"id\": vector_id,\n",
    "                        \"values\": embedding.tolist(),\n",
    "                        \"metadata\": metadata\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            print(f\"Successfully stored embedding for {file_name} in Pinecone\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error storing embeddings: {e}\")\n",
    "        return False\n",
    "\n",
    "# Function to process a specific folder\n",
    "def process_folder(folder_name, max_files=5):\n",
    "    \"\"\"Process a specific folder containing resumes, limited to max_files per file type.\"\"\"\n",
    "    # Create index if it doesn't exist\n",
    "    # create_index_if_not_exists()\n",
    "\n",
    "    print(f\"Processing folder: {folder_name}\")\n",
    "\n",
    "    # Process PDF files (up to max_files)\n",
    "    pdf_data = extract_pdf_text(folder_name, max_files)\n",
    "    if pdf_data:\n",
    "        store_embeddings(pdf_data, folder_name)\n",
    "\n",
    "    # Process TXT files (up to max_files)\n",
    "    txt_data = extract_txt_text(folder_name, max_files)\n",
    "    if txt_data:\n",
    "        store_embeddings(txt_data, folder_name)\n",
    "\n",
    "    print(f\"Finished processing folder: {folder_name}\")\n",
    "\n",
    "# Function to rank resume\n",
    "def rank_resume(result_details):\n",
    "    \"\"\"\n",
    "    Rank a resume using the API\n",
    "\n",
    "    Args:\n",
    "        result_details (dict): Resume details to rank\n",
    "\n",
    "    Returns:\n",
    "        dict: Ranked resume with score\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {bearer_token_2}',\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'stream': 'false',\n",
    "    }\n",
    "\n",
    "    json_data = {\n",
    "        'input_value': 'message',\n",
    "        'output_type': 'chat',\n",
    "        'input_type': 'chat',\n",
    "        'tweaks': {\n",
    "            'Agent-ZGHPJ': {\n",
    "                'add_current_date_tool': True,\n",
    "                'agent_description': 'A helpful assistant with access to the following tools:',\n",
    "                'agent_llm': 'Google Generative AI',\n",
    "                'handle_parsing_errors': True,\n",
    "                'input_value': '',\n",
    "                'max_iterations': 15,\n",
    "                'n_messages': 100,\n",
    "                'order': 'Ascending',\n",
    "                'sender': 'Machine and User',\n",
    "                'sender_name': '',\n",
    "                'session_id': '',\n",
    "                'system_prompt': 'You are a helpful assistant that can use tools to answer questions and perform tasks.',\n",
    "                'template': '{sender_name}: {text}',\n",
    "                'verbose': True,\n",
    "                # 'max_output_tokens': None,\n",
    "                'model_name': 'learnlm-1.5-pro-experimental',\n",
    "                'api_key': google_api,\n",
    "                # 'top_p': None,\n",
    "                'temperature': 0,\n",
    "                # 'n': None,\n",
    "                # 'top_k': None,\n",
    "                'tool_model_enabled': False,\n",
    "            },\n",
    "            'Prompt-cwlsj': {\n",
    "                'template': '\\nExtract the following with only fields from the given input also refine score as per jd matching if you want and return valid JSON:\\n\\n- id\\n- score\\n- folder\\n- file\\n- preview\\n- name\\n- skills (as a list)\\n- experience\\n- education\\n- location\\n\\nSet any missing field to null. Only output JSON.\\n\\nInput:\\n\\\\\"\\\\\"\\\\\"\\n{result_details}\\n\\\\\"\\\\\"\\\\\"\\n\\n',\n",
    "                'tool_placeholder': '',\n",
    "                'result_details': json.dumps(result_details),\n",
    "            },\n",
    "            'ChatOutput-NMGIM': {\n",
    "                'background_color': '',\n",
    "                'chat_icon': '',\n",
    "                'clean_data': True,\n",
    "                'data_template': '{text}',\n",
    "                'sender': 'Machine',\n",
    "                'sender_name': 'AI',\n",
    "                'session_id': '',\n",
    "                'should_store_message': True,\n",
    "                'text_color': '',\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            'https://api.langflow.astra.datastax.com/lf/ad6e8f21-6c0a-4de7-b59c-837f011e58f2/api/v1/run/017d81dc-f6ba-4eeb-b27f-f363fb7a6bba',\n",
    "            params=params,\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "\n",
    "        response_data = response.json()\n",
    "        chat_response = response_data[\"outputs\"][0][\"outputs\"][0][\"results\"][\"message\"][\"data\"][\"text\"]\n",
    "        match = re.search(r'{.*}', chat_response, re.DOTALL)\n",
    "        if match:\n",
    "            result_dict = json.loads(match.group(0))\n",
    "            return result_dict\n",
    "        else:\n",
    "            return {\"id\": result_details[\"id\"], \"score\": result_details[\"score\"]}\n",
    "    except Exception as e:\n",
    "        print(f\"Error ranking resume: {e}\")\n",
    "        return {\"id\": result_details[\"id\"], \"score\": result_details[\"score\"]}\n",
    "\n",
    "# Function to search resumes across multiple folders\n",
    "def search_resumes(folder_names, query_text, top_k=5):\n",
    "    \"\"\"\n",
    "    Search for resumes in multiple folders and return ranked results\n",
    "\n",
    "    Args:\n",
    "        folder_names (list): List of folder names containing resumes\n",
    "        query_text (str): Query text to search for\n",
    "        top_k (int): Number of top results to return\n",
    "\n",
    "    Returns:\n",
    "        list: Ranked resumes with their details\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    # First, process all folders to ensure they're indexed\n",
    "    for folder in folder_names:\n",
    "        process_folder(folder, max_files=5)\n",
    "\n",
    "    # Generate embeddings for the query\n",
    "    query_embedding = generate_embeddings(query_text)\n",
    "\n",
    "    try:\n",
    "        # Get the index\n",
    "        index = pc.Index(index_name)\n",
    "\n",
    "        # Search for similar vectors\n",
    "        results = index.query(\n",
    "            vector=query_embedding.tolist(),\n",
    "            top_k=top_k * len(folder_names),\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        # Process each result\n",
    "        if results and 'matches' in results:\n",
    "            for match in results['matches']:\n",
    "                result_details = {\n",
    "                    \"id\": match['id'],\n",
    "                    \"score\": float(match['score']),  # Convert to float to ensure it's JSON serializable\n",
    "                    \"folder\": match['metadata'].get('folder_name'),\n",
    "                    \"file\": match['metadata'].get('file_name'),\n",
    "                    \"preview\": match['metadata'].get('text_sample')[:500]  # Limit text sample size\n",
    "                }\n",
    "\n",
    "                # Pass each result to rank_resume function\n",
    "                ranked_result = rank_resume(result_details)\n",
    "\n",
    "                # Add to all results\n",
    "                all_results.append(ranked_result)\n",
    "\n",
    "        # Sort results by score in descending order\n",
    "        sorted_results = sorted(all_results, key=lambda x: float(x.get('score', 0)), reverse=True)\n",
    "\n",
    "        # Return top results\n",
    "        return sorted_results[:top_k]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for resumes: {e}\")\n",
    "        return []\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def index():\n",
    "    results = []\n",
    "    if request.method == \"POST\":\n",
    "        jd = request.form.get(\"jd\")\n",
    "        create_index_if_not_exists()\n",
    "        folders = get_drive_folder()\n",
    "        folder_names = get_folder_name(jd, folders)\n",
    "        results = search_resumes(folder_names, jd, top_k=3)\n",
    "    return render_template(\"index.html\", results=results)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = 9800  # Choose a port\n",
    "    print(f\"Flask App Running: {eval_js('google.colab.kernel.proxyPort({})'.format(port))}\")\n",
    "    app.run(port=port, debug=False)\n",
    "# # Main function\n",
    "# def main():\n",
    "#     # List of folders to process\n",
    "#     # folder_names = [\"ENGINEERING\"]  # Replace with your actual folder names\n",
    "\n",
    "#     # Search query\n",
    "#     jd= input('Enter job description')\n",
    "#     create_index_if_not_exists()\n",
    "#     folders=get_drive_folder()\n",
    "#     folder_names=get_folder_name(jd,folders)\n",
    "#     print(folder_names)\n",
    "#     print(f\"Searching for: {jd}\")\n",
    "\n",
    "#     # Search for resumes across all folders\n",
    "#     results = search_resumes(folder_names, jd, top_k=3)\n",
    "\n",
    "#     # Display results\n",
    "#     if results:\n",
    "#         print(\"\\nTop ranked resumes:\")\n",
    "#         for i, result in enumerate(results, 1):\n",
    "#             print(f\"\\nRank {i}:\")\n",
    "#             print(f\"I: {result.get('id')}\")\n",
    "#             print(f\"Score: {result.get('score')}\")\n",
    "#             print(f\"Name: {result.get('name')}\")\n",
    "#             print(f\"Folder: {result.get('folder')}\")\n",
    "#             print(f\"File: {result.get('file')}\")\n",
    "#             print(f\"Skills: {result.get('skills')}\")\n",
    "#             print(f\"Experience: {result.get('experience')}\")\n",
    "#             print(f\"Education: {result.get('education')}\")\n",
    "#             print(f\"Location: {result.get('location')}\")\n",
    "#     else:\n",
    "#         print(\"No results found.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
